# -*- coding: utf-8 -*-
"""Final_code-inp.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1JUXRlkQSAUoaKW1dp8okuVLre97-vpix
"""

pip install plotly==5.11.0

pip install tensorflow

# Commented out IPython magic to ensure Python compatibility.
#importing libraries
import numpy as np 
import pandas as pd
import random as rd

#data visualization
import matplotlib.pyplot as plt
# %matplotlib inline
import seaborn as sns
import plotly.express as px
from PIL import Image

#for the CNN model
from sklearn.model_selection import train_test_split
from sklearn.metrics import confusion_matrix
from sklearn.metrics import classification_report
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers
from tensorflow.keras.layers.experimental import preprocessing
from keras.preprocessing.image import ImageDataGenerator

#downloading the training data
import pandas as pd
train = pd.read_csv("sign_mnist_train.csv")
train.head()

#downloading the test data
test = pd.read_csv("sign_mnist_test.csv")
test.head()

#summing the number of na in the training set for each column
print(sum(train.isna().sum()))

#summing the number of na in the test set for each column
print(sum(test.isna().sum()))

#summing the number of null values in the training set for each column
print(sum(train.isnull().sum()))

#summing the number of null values in the test set for each column
print(sum(test.isnull().sum()))

#creating our Y for the training data
Y_train = train["label"]

#creating our X for the training data
X_train = train.drop(labels = ["label"],axis = 1)

#creating our Y for the test data
Y_test = test["label"]

#creating our X for the training data
X_test = test.drop(labels = ["label"],axis = 1)

#converting the range of the pixel data from 0-255 to 0-1
X_train = X_train / 255.0

X_test = X_test / 255.0

X_train = X_train.values.reshape(-1,28,28,1)
X_test = X_test.values.reshape(-1,28,28,1)
print(X_train.shape)
print(X_test.shape)

fig = px.histogram(train, 
                   x='label', 
                   color = 'label',
                   title="Distrubition of Labels in the Training Set",
                   width=700, height=500)
fig.show()

#creating an interactive bar graph that shows the distrubition of labels within the test set
fig = px.histogram(test, 
                   x='label',
                   color = 'label',
                   title="Distrubition of Labels in the Test Set",
                   width=700, height=500)
fig.show()

fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10),
                        subplot_kw={'xticks': [], 'yticks': []})

for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X_train[i][:,:,0], cmap='gray')
    plt.title(Y_train[i])
plt.show()

#creating a 5x5 grid of the first 25 photos in the test images
fig, axes = plt.subplots(nrows=5, ncols=5, figsize=(15, 10),
                        subplot_kw={'xticks': [], 'yticks': []})

for i in range(25):
    plt.subplot(5,5,i+1)
    plt.imshow(X_test[i][:,:,0], cmap='gray')
    plt.title(Y_test[i])
plt.show()

#spliting training images into the images we will use for training the model and validating the model
X_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size = 0.3, random_state=7)

#creating our CNN model
model = keras.Sequential([
    
    layers.BatchNormalization(),
    layers.Conv2D(filters=32, kernel_size=(5,5), activation="relu", padding='same',
                  input_shape=[28, 28, 1]),
    layers.MaxPool2D(),
    layers.Dropout(.25),
    
    layers.BatchNormalization(),
    layers.Conv2D(filters=32, kernel_size=(3,3), activation="relu", padding='same'),
    layers.MaxPool2D(),
    layers.Dropout(.25),
    
    layers.BatchNormalization(),
    layers.Conv2D(filters=64, kernel_size=(3,3), activation="relu", padding='same'),
    layers.MaxPool2D(),
    layers.Dropout(.25),

    layers.BatchNormalization(),
    layers.Conv2D(filters=128, kernel_size=(3,3), activation="relu", padding='same'),
    layers.MaxPool2D(),
    layers.Dropout(.25),
    
    layers.Flatten(),
    layers.Dropout(.25),
    layers.Dense(units=64, activation="relu"),
    layers.Dense(units=26, activation="softmax"),
])

#compiling the model
model.compile(
    optimizer=tf.keras.optimizers.Adam(epsilon=0.01),
    loss='sparse_categorical_crossentropy',
    metrics=['accuracy']
)

history2=model.fit(
    x = X_train,
    y = Y_train,
    validation_data= (X_val,Y_val),
    batch_size = 128,
    epochs=20,
    verbose=2,
)

#Viewing the training results
history_frame = pd.DataFrame(history2.history)
history_frame.loc[:, ['loss', 'val_loss']].plot()
history_frame.loc[:, ['accuracy', 'val_accuracy']].plot();

#creating our predictions using the test pixel values
predictions = model.predict(X_test)
predictions = np.argmax(predictions,axis = 1)

#creating a report that show how our predictions compare with actual values
print(classification_report(Y_test, predictions))

import pickle
pickle.dump(model, open('model.pkl', 'wb'))

!pip install streamlit

!pip install --upgrade pip
!pip install gTTS

# Commented out IPython magic to ensure Python compatibility.
# %%writefile test.py
# import numpy as np
# import streamlit as st
# import matplotlib.pyplot as plt
# import tensorflow as tf
# import cv2
# from numpy import resize
# import os
# import pickle
# from PIL import Image
# from gtts import gTTS
# 
# st.write("sign language translator")
# var = ''
# uploaded_files = st.file_uploader("Choose an image", accept_multiple_files=True)
# for uploaded_file in uploaded_files:
#     st.success("Successfully image uplaoded", icon="âœ…")
# 
# 
# def value(uploaded_files):
#   pickled_model = pickle.load(open('model.pkl', 'rb'))
# 
#       numpy_image = cv2.cvtColor(uploaded_files, cv2.COLOR_BGR2GRAY)
#       image = cv2.resize(numpy_image, (28, 28)).astype(np.float32)
#       image2 = image.reshape(-1)
#       image2 = image2.reshape([1,28,28,1])
#       
#       yhat = pickled_model.predict(image2)
# 
# 
#       alphabets = list(map(chr, range(ord('A'), ord('Y') + 1)))
#       alphabets.remove('J')
#       index = yhat[0].argmax()
#       st.write(alphabets[index-3])
#       return alphabets[index-3]
# 
# 
# 
# 
# def prediction(uploaded_files):
#     pickled_model = pickle.load(open('model.pkl', 'rb'))
#     var = value(uploaded_files)
#     
#    
#     
#     text_en = var
#     ta_tts = gTTS(text_en)
#     ta_tts.save('trans.mp3')
#     audio_file = open('trans.mp3', 'rb')
#     audio_bytes = audio_file.read()
#     st.audio(audio_bytes, format='audio / ogg', start_time=0)
# 
# 
# if uploaded_files:
#     if st.button('Predict'):
#         st.write('Answer')
#         prediction(uploaded_files)
#     else:
#         st.write('')
# 
# else:
#     st.error("Please upload an image to predict")
# 
#

!streamlit run test.py & npx localtunnel --port 8501